import os
import torch
import numpy as np
from PIL import Image
import imageio
import argparse
from diffsynth import WanVideoReCamMasterPipeline, ModelManager
from tqdm import tqdm
import json

class VideoDecoder:
    def __init__(self, vae_path, device="cuda"):
        """åˆå§‹åŒ–è§†é¢‘è§£ç å™¨"""
        self.device = device
        
        # åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨
        model_manager = ModelManager(torch_dtype=torch.bfloat16, device="cpu")
        model_manager.load_models([vae_path])
        
        # åˆ›å»ºpipelineå¹¶åªä¿ç•™VAE
        self.pipe = WanVideoReCamMasterPipeline.from_model_manager(model_manager)
        self.pipe = self.pipe.to(device)
        
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šç¡®ä¿VAEåŠå…¶æ‰€æœ‰ç»„ä»¶éƒ½åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
        self.pipe.vae = self.pipe.vae.to(device)
        if hasattr(self.pipe.vae, 'model'):
            self.pipe.vae.model = self.pipe.vae.model.to(device)
        
        print(f"âœ… VAEè§£ç å™¨åˆå§‹åŒ–å®Œæˆï¼Œè®¾å¤‡: {device}")

    def decode_latents_to_video(self, latents, output_path, tiled=True, tile_size=(34, 34), tile_stride=(18, 16)):
        """
        å°†latentsè§£ç ä¸ºè§†é¢‘ - ä¿®æ­£ç‰ˆæœ¬ï¼Œä¿®å¤ç»´åº¦å¤„ç†é—®é¢˜
        """
        print(f"ğŸ”§ å¼€å§‹è§£ç latents...")
        print(f"è¾“å…¥latentså½¢çŠ¶: {latents.shape}")
        print(f"è¾“å…¥latentsè®¾å¤‡: {latents.device}")
        print(f"è¾“å…¥latentsæ•°æ®ç±»å‹: {latents.dtype}")
        
        # ç¡®ä¿latentsæœ‰batchç»´åº¦
        if len(latents.shape) == 4:  # [C, T, H, W]
            latents = latents.unsqueeze(0)  # -> [1, C, T, H, W]
        
        # ğŸ”§ å…³é”®ä¿®æ­£ï¼šç¡®ä¿latentsåœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Šä¸”æ•°æ®ç±»å‹åŒ¹é…
        model_dtype = next(self.pipe.vae.parameters()).dtype
        model_device = next(self.pipe.vae.parameters()).device
        
        print(f"æ¨¡å‹è®¾å¤‡: {model_device}")
        print(f"æ¨¡å‹æ•°æ®ç±»å‹: {model_dtype}")
        
        # å°†latentsç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡å’Œæ•°æ®ç±»å‹
        latents = latents.to(device=model_device, dtype=model_dtype)
        
        print(f"è§£ç latentså½¢çŠ¶: {latents.shape}")
        print(f"è§£ç latentsè®¾å¤‡: {latents.device}")
        print(f"è§£ç latentsæ•°æ®ç±»å‹: {latents.dtype}")
        
        # ğŸ”§ å¼ºåˆ¶è®¾ç½®pipelineè®¾å¤‡ï¼Œç¡®ä¿æ‰€æœ‰æ“ä½œåœ¨åŒä¸€è®¾å¤‡ä¸Š
        self.pipe.device = model_device
        
        # ä½¿ç”¨VAEè§£ç 
        with torch.no_grad():
            try:
                if tiled:
                    print("ğŸ”§ å°è¯•tiledè§£ç ...")
                    decoded_video = self.pipe.decode_video(
                        latents, 
                        tiled=True, 
                        tile_size=tile_size, 
                        tile_stride=tile_stride
                    )
                else:
                    print("ğŸ”§ ä½¿ç”¨étiledè§£ç ...")
                    decoded_video = self.pipe.decode_video(latents, tiled=False)
                    
            except Exception as e:
                print(f"decode_videoå¤±è´¥ï¼Œé”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
                
                # ğŸ”§ fallback: å°è¯•ç›´æ¥è°ƒç”¨VAE
                try:
                    print("ğŸ”§ å°è¯•ç›´æ¥è°ƒç”¨VAEè§£ç ...")
                    decoded_video = self.pipe.vae.decode(
                        latents.squeeze(0),  # ç§»é™¤batchç»´åº¦ [C, T, H, W]
                        device=model_device, 
                        tiled=False
                    )
                    # æ‰‹åŠ¨è°ƒæ•´ç»´åº¦: VAEè¾“å‡º [T, H, W, C] -> [1, T, H, W, C]
                    if len(decoded_video.shape) == 4:  # [T, H, W, C]
                        decoded_video = decoded_video.unsqueeze(0)  # -> [1, T, H, W, C]
                except Exception as e2:
                    print(f"ç›´æ¥VAEè§£ç ä¹Ÿå¤±è´¥: {e2}")
                    raise e2
        
        print(f"è§£ç åè§†é¢‘å½¢çŠ¶: {decoded_video.shape}")
        
        # ğŸ”§ å…³é”®ä¿®æ­£ï¼šæ­£ç¡®å¤„ç†ç»´åº¦é¡ºåº
        video_np = None
        
        if len(decoded_video.shape) == 5:
            # æ£€æŸ¥ä¸åŒçš„å¯èƒ½ç»´åº¦é¡ºåº
            if decoded_video.shape == torch.Size([1, 3, 113, 480, 832]):
                # æ ¼å¼: [B, C, T, H, W] -> éœ€è¦è½¬æ¢ä¸º [T, H, W, C]
                print("ğŸ”§ æ£€æµ‹åˆ°æ ¼å¼: [B, C, T, H, W]")
                video_np = decoded_video[0].permute(1, 2, 3, 0).to(torch.float32).cpu().numpy()  # [T, H, W, C]
            elif decoded_video.shape[1] == 3:
                # å¦‚æœç¬¬äºŒä¸ªç»´åº¦æ˜¯3ï¼Œå¯èƒ½æ˜¯ [B, C, T, H, W]
                print("ğŸ”§ æ£€æµ‹åˆ°å¯èƒ½çš„æ ¼å¼: [B, C, T, H, W]")
                video_np = decoded_video[0].permute(1, 2, 3, 0).to(torch.float32).cpu().numpy()  # [T, H, W, C]
            elif decoded_video.shape[-1] == 3:
                # å¦‚æœæœ€åä¸€ä¸ªç»´åº¦æ˜¯3ï¼Œå¯èƒ½æ˜¯ [B, T, H, W, C]
                print("ğŸ”§ æ£€æµ‹åˆ°æ ¼å¼: [B, T, H, W, C]")
                video_np = decoded_video[0].to(torch.float32).cpu().numpy()  # [T, H, W, C]
            else:
                # å°è¯•æ‰¾åˆ°ç»´åº¦ä¸º3çš„ä½ç½®
                shape = list(decoded_video.shape)
                if 3 in shape:
                    channel_dim = shape.index(3)
                    print(f"ğŸ”§ æ£€æµ‹åˆ°é€šé“ç»´åº¦åœ¨ä½ç½®: {channel_dim}")
                    
                    if channel_dim == 1:  # [B, C, T, H, W]
                        video_np = decoded_video[0].permute(1, 2, 3, 0).to(torch.float32).cpu().numpy()
                    elif channel_dim == 4:  # [B, T, H, W, C]
                        video_np = decoded_video[0].to(torch.float32).cpu().numpy()
                    else:
                        print(f"âš ï¸ æœªçŸ¥çš„é€šé“ç»´åº¦ä½ç½®: {channel_dim}")
                        raise ValueError(f"Cannot handle channel dimension at position {channel_dim}")
                else:
                    print(f"âš ï¸ æœªæ‰¾åˆ°é€šé“ç»´åº¦ä¸º3çš„ä½ç½®ï¼Œå½¢çŠ¶: {decoded_video.shape}")
                    raise ValueError(f"Cannot find channel dimension of size 3 in shape {decoded_video.shape}")
                    
        elif len(decoded_video.shape) == 4:
            # 4ç»´å¼ é‡ï¼Œæ£€æŸ¥å¯èƒ½çš„æ ¼å¼
            if decoded_video.shape[-1] == 3:  # [T, H, W, C]
                video_np = decoded_video.to(torch.float32).cpu().numpy()
            elif decoded_video.shape[0] == 3:  # [C, T, H, W]
                video_np = decoded_video.permute(1, 2, 3, 0).to(torch.float32).cpu().numpy()
            else:
                print(f"âš ï¸ æ— æ³•å¤„ç†çš„4Dè§†é¢‘å½¢çŠ¶: {decoded_video.shape}")
                raise ValueError(f"Cannot handle 4D video tensor shape: {decoded_video.shape}")
        else:
            print(f"âš ï¸ æ„å¤–çš„è§†é¢‘ç»´åº¦æ•°: {len(decoded_video.shape)}")
            raise ValueError(f"Unexpected video tensor dimensions: {decoded_video.shape}")
        
        if video_np is None:
            raise ValueError("Failed to convert video tensor to numpy array")
            
        print(f"è½¬æ¢åè§†é¢‘æ•°ç»„å½¢çŠ¶: {video_np.shape}")
        
        # ğŸ”§ éªŒè¯æœ€ç»ˆå½¢çŠ¶
        if len(video_np.shape) != 4:
            raise ValueError(f"Expected 4D array [T, H, W, C], got {video_np.shape}")
        
        if video_np.shape[-1] != 3:
            print(f"âš ï¸ é€šé“æ•°å¼‚å¸¸: æœŸæœ›3ï¼Œå®é™…{video_np.shape[-1]}")
            print(f"å®Œæ•´å½¢çŠ¶: {video_np.shape}")
            # å°è¯•å…¶ä»–ç»´åº¦æ’åˆ—
            if video_np.shape[0] == 3:  # [C, T, H, W]
                print("ğŸ”§ å°è¯•é‡æ–°æ’åˆ—: [C, T, H, W] -> [T, H, W, C]")
                video_np = np.transpose(video_np, (1, 2, 3, 0))
            elif video_np.shape[1] == 3:  # [T, C, H, W]
                print("ğŸ”§ å°è¯•é‡æ–°æ’åˆ—: [T, C, H, W] -> [T, H, W, C]")
                video_np = np.transpose(video_np, (0, 2, 3, 1))
            else:
                raise ValueError(f"Expected 3 channels (RGB), got {video_np.shape[-1]} channels")
        
        # åå½’ä¸€åŒ–
        video_np = (video_np * 0.5 + 0.5).clip(0, 1)  # åå½’ä¸€åŒ–
        video_np = (video_np * 255).astype(np.uint8)
        
        print(f"æœ€ç»ˆè§†é¢‘æ•°ç»„å½¢çŠ¶: {video_np.shape}")
        print(f"è§†é¢‘æ•°ç»„å€¼èŒƒå›´: {video_np.min()} - {video_np.max()}")
        
        # ä¿å­˜è§†é¢‘
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        try:
            with imageio.get_writer(output_path, fps=10, quality=8) as writer:
                for frame_idx, frame in enumerate(video_np):
                    # ğŸ”§ éªŒè¯æ¯ä¸€å¸§çš„å½¢çŠ¶
                    if len(frame.shape) != 3 or frame.shape[-1] != 3:
                        print(f"âš ï¸ å¸§ {frame_idx} å½¢çŠ¶å¼‚å¸¸: {frame.shape}")
                        continue
                    
                    writer.append_data(frame)
                    if frame_idx % 10 == 0:
                        print(f"  å†™å…¥å¸§ {frame_idx}/{len(video_np)}")
        except Exception as e:
            print(f"ä¿å­˜è§†é¢‘å¤±è´¥: {e}")
            # ğŸ”§ å°è¯•ä¿å­˜å‰å‡ å¸§ä¸ºå›¾ç‰‡è¿›è¡Œè°ƒè¯•
            debug_dir = os.path.join(os.path.dirname(output_path), "debug_frames")
            os.makedirs(debug_dir, exist_ok=True)
            
            for i in range(min(5, len(video_np))):
                frame = video_np[i]
                debug_path = os.path.join(debug_dir, f"debug_frame_{i}.png")
                try:
                    if len(frame.shape) == 3 and frame.shape[-1] == 3:
                        Image.fromarray(frame).save(debug_path)
                        print(f"è°ƒè¯•: ä¿å­˜å¸§ {i} åˆ° {debug_path}")
                    else:
                        print(f"è°ƒè¯•: å¸§ {i} å½¢çŠ¶å¼‚å¸¸: {frame.shape}")
                except Exception as e2:
                    print(f"è°ƒè¯•: ä¿å­˜å¸§ {i} å¤±è´¥: {e2}")
            raise e
        
        print(f"âœ… è§†é¢‘ä¿å­˜åˆ°: {output_path}")
        return video_np

    def save_frames_as_images(self, video_np, output_dir, prefix="frame"):
        """å°†è§†é¢‘å¸§ä¿å­˜ä¸ºå•ç‹¬çš„å›¾åƒæ–‡ä»¶"""
        os.makedirs(output_dir, exist_ok=True)
        
        for i, frame in enumerate(video_np):
            frame_path = os.path.join(output_dir, f"{prefix}_{i:04d}.png")
            # ğŸ”§ éªŒè¯å¸§å½¢çŠ¶
            if len(frame.shape) == 3 and frame.shape[-1] == 3:
                Image.fromarray(frame).save(frame_path)
            else:
                print(f"âš ï¸ è·³è¿‡å½¢çŠ¶å¼‚å¸¸çš„å¸§ {i}: {frame.shape}")
        
        print(f"âœ… ä¿å­˜äº† {len(video_np)} å¸§åˆ°: {output_dir}")

def decode_single_episode(encoded_pth_path, vae_path, output_base_dir, device="cuda"):
    """è§£ç å•ä¸ªepisodeçš„ç¼–ç æ•°æ® - ä¿®æ­£ç‰ˆæœ¬"""
    print(f"\nğŸ”§ è§£ç episode: {encoded_pth_path}")
    
    # åŠ è½½ç¼–ç æ•°æ®
    try:
        encoded_data = torch.load(encoded_pth_path, weights_only=False, map_location="cpu")
        print(f"âœ… æˆåŠŸåŠ è½½ç¼–ç æ•°æ®")
    except Exception as e:
        print(f"âŒ åŠ è½½ç¼–ç æ•°æ®å¤±è´¥: {e}")
        return False
    
    # æ£€æŸ¥æ•°æ®ç»“æ„
    print("ğŸ” ç¼–ç æ•°æ®ç»“æ„:")
    for key, value in encoded_data.items():
        if isinstance(value, torch.Tensor):
            print(f"  - {key}: {value.shape}, dtype: {value.dtype}, device: {value.device}")
        elif isinstance(value, dict):
            print(f"  - {key}: dict with keys {list(value.keys())}")
        else:
            print(f"  - {key}: {type(value)}")
    
    # è·å–latents
    latents = encoded_data.get('latents')
    if latents is None:
        print("âŒ æœªæ‰¾åˆ°latentsæ•°æ®")
        return False
    
    # ğŸ”§ ç¡®ä¿latentsåœ¨CPUä¸Šï¼ˆåŠ è½½æ—¶çš„é»˜è®¤çŠ¶æ€ï¼‰
    if latents.device != torch.device('cpu'):
        latents = latents.cpu()
        print(f"ğŸ”§ å°†latentsç§»åŠ¨åˆ°CPU: {latents.device}")
    
    episode_info = encoded_data.get('episode_info', {})
    episode_idx = episode_info.get('episode_idx', 'unknown')
    total_frames = episode_info.get('total_frames', latents.shape[1] * 4)  # ä¼°ç®—åŸå§‹å¸§æ•°
    
    print(f"Episodeä¿¡æ¯:")
    print(f"  - Episodeç´¢å¼•: {episode_idx}")
    print(f"  - Latentså½¢çŠ¶: {latents.shape}")
    print(f"  - Latentsè®¾å¤‡: {latents.device}")
    print(f"  - Latentsæ•°æ®ç±»å‹: {latents.dtype}")
    print(f"  - åŸå§‹æ€»å¸§æ•°: {total_frames}")
    print(f"  - å‹ç¼©åå¸§æ•°: {latents.shape[1]}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    episode_name = f"episode_{episode_idx:06d}" if isinstance(episode_idx, int) else f"episode_{episode_idx}"
    output_dir = os.path.join(output_base_dir, episode_name)
    os.makedirs(output_dir, exist_ok=True)
    
    # åˆå§‹åŒ–è§£ç å™¨
    try:
        decoder = VideoDecoder(vae_path, device)
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–è§£ç å™¨å¤±è´¥: {e}")
        return False
    
    # è§£ç ä¸ºè§†é¢‘
    video_output_path = os.path.join(output_dir, "decoded_video.mp4")
    try:
        video_np = decoder.decode_latents_to_video(
            latents, 
            video_output_path,
            tiled=False,  # ğŸ”§ é¦–å…ˆå°è¯•étiledè§£ç ï¼Œé¿å…tiledçš„å¤æ‚æ€§
            tile_size=(34, 34),
            tile_stride=(18, 16)
        )
        
        # ä¿å­˜å‰å‡ å¸§ä¸ºå›¾åƒï¼ˆç”¨äºå¿«é€Ÿæ£€æŸ¥ï¼‰
        frames_dir = os.path.join(output_dir, "frames")
        sample_frames = video_np[:min(10, len(video_np))]  # åªä¿å­˜å‰10å¸§
        decoder.save_frames_as_images(sample_frames, frames_dir, f"frame_{episode_idx}")
        
        # ä¿å­˜è§£ç ä¿¡æ¯
        decode_info = {
            "source_pth": encoded_pth_path,
            "decoded_video_path": video_output_path,
            "latents_shape": list(latents.shape),
            "decoded_video_shape": list(video_np.shape),
            "original_total_frames": total_frames,
            "decoded_frames": len(video_np),
            "compression_ratio": total_frames / len(video_np) if len(video_np) > 0 else 0,
            "latents_dtype": str(latents.dtype),
            "latents_device": str(latents.device),
            "vae_compression_ratio": total_frames / latents.shape[1] if latents.shape[1] > 0 else 0
        }
        
        info_path = os.path.join(output_dir, "decode_info.json")
        with open(info_path, 'w') as f:
            json.dump(decode_info, f, indent=2)
        
        print(f"âœ… Episode {episode_idx} è§£ç å®Œæˆ")
        print(f"  - åŸå§‹å¸§æ•°: {total_frames}")
        print(f"  - è§£ç å¸§æ•°: {len(video_np)}")
        print(f"  - å‹ç¼©æ¯”: {decode_info['compression_ratio']:.2f}")
        print(f"  - VAEæ—¶é—´å‹ç¼©æ¯”: {decode_info['vae_compression_ratio']:.2f}")
        return True
        
    except Exception as e:
        print(f"âŒ è§£ç å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def batch_decode_episodes(encoded_base_dir, vae_path, output_base_dir, max_episodes=None, device="cuda"):
    """æ‰¹é‡è§£ç episodes"""
    print(f"ğŸ”§ æ‰¹é‡è§£ç Open-X episodes")
    print(f"æºç›®å½•: {encoded_base_dir}")
    print(f"è¾“å‡ºç›®å½•: {output_base_dir}")
    
    # æŸ¥æ‰¾æ‰€æœ‰ç¼–ç çš„episodes
    episode_dirs = []
    if os.path.exists(encoded_base_dir):
        for item in sorted(os.listdir(encoded_base_dir)):  # æ’åºç¡®ä¿ä¸€è‡´æ€§
            episode_dir = os.path.join(encoded_base_dir, item)
            if os.path.isdir(episode_dir):
                encoded_path = os.path.join(episode_dir, "encoded_video.pth")
                if os.path.exists(encoded_path):
                    episode_dirs.append(encoded_path)
    
    print(f"æ‰¾åˆ° {len(episode_dirs)} ä¸ªç¼–ç çš„episodes")
    
    if max_episodes and len(episode_dirs) > max_episodes:
        episode_dirs = episode_dirs[:max_episodes]
        print(f"é™åˆ¶å¤„ç†å‰ {max_episodes} ä¸ªepisodes")
    
    # æ‰¹é‡è§£ç 
    success_count = 0
    for i, encoded_pth_path in enumerate(tqdm(episode_dirs, desc="è§£ç episodes")):
        print(f"\n{'='*60}")
        print(f"å¤„ç† {i+1}/{len(episode_dirs)}: {os.path.basename(os.path.dirname(encoded_pth_path))}")
        
        success = decode_single_episode(encoded_pth_path, vae_path, output_base_dir, device)
        if success:
            success_count += 1
        
        print(f"å½“å‰æˆåŠŸç‡: {success_count}/{i+1} ({success_count/(i+1)*100:.1f}%)")
    
    print(f"\nğŸ‰ æ‰¹é‡è§£ç å®Œæˆ!")
    print(f"æ€»å¤„ç†: {len(episode_dirs)} ä¸ªepisodes")
    print(f"æˆåŠŸè§£ç : {success_count} ä¸ªepisodes")
    print(f"æˆåŠŸç‡: {success_count/len(episode_dirs)*100:.1f}%")

def main():
    parser = argparse.ArgumentParser(description="è§£ç Open-Xç¼–ç çš„latentsä»¥éªŒè¯æ­£ç¡®æ€§ - ä¿®æ­£ç‰ˆæœ¬")
    parser.add_argument("--mode", type=str, choices=["single", "batch"], default="batch",
                       help="è§£ç æ¨¡å¼ï¼šsingle (å•ä¸ªepisode) æˆ– batch (æ‰¹é‡)")
    parser.add_argument("--encoded_pth", type=str, 
                       default="/share_zhuyixuan05/zhuyixuan05/openx-fractal-encoded/episode_000000/encoded_video.pth",
                       help="å•ä¸ªç¼–ç æ–‡ä»¶è·¯å¾„ï¼ˆsingleæ¨¡å¼ï¼‰")
    parser.add_argument("--encoded_base_dir", type=str,
                       default="/share_zhuyixuan05/zhuyixuan05/openx-fractal-encoded",
                       help="ç¼–ç æ•°æ®åŸºç¡€ç›®å½•ï¼ˆbatchæ¨¡å¼ï¼‰")
    parser.add_argument("--vae_path", type=str,
                       default="models/Wan-AI/Wan2.1-T2V-1.3B/Wan2.1_VAE.pth",
                       help="VAEæ¨¡å‹è·¯å¾„")
    parser.add_argument("--output_dir", type=str,
                       default="./decoded_results_fixed",
                       help="è§£ç è¾“å‡ºç›®å½•")
    parser.add_argument("--max_episodes", type=int, default=5,
                       help="æœ€å¤§è§£ç episodesæ•°é‡ï¼ˆbatchæ¨¡å¼ï¼Œç”¨äºæµ‹è¯•ï¼‰")
    parser.add_argument("--device", type=str, default="cuda",
                       help="è®¡ç®—è®¾å¤‡")
    
    args = parser.parse_args()
    
    print("ğŸ”§ Open-X Latents è§£ç éªŒè¯å·¥å…· (ä¿®æ­£ç‰ˆæœ¬ - Fixed)")
    print(f"æ¨¡å¼: {args.mode}")
    print(f"VAEè·¯å¾„: {args.vae_path}")
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"è®¾å¤‡: {args.device}")
    
    # ğŸ”§ æ£€æŸ¥CUDAå¯ç”¨æ€§
    if args.device == "cuda" and not torch.cuda.is_available():
        print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°CPU")
        args.device = "cpu"
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(args.output_dir, exist_ok=True)
    
    if args.mode == "single":
        print(f"è¾“å…¥æ–‡ä»¶: {args.encoded_pth}")
        if not os.path.exists(args.encoded_pth):
            print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.encoded_pth}")
            return
        
        success = decode_single_episode(args.encoded_pth, args.vae_path, args.output_dir, args.device)
        if success:
            print("âœ… å•ä¸ªepisodeè§£ç æˆåŠŸ")
        else:
            print("âŒ å•ä¸ªepisodeè§£ç å¤±è´¥")
    
    elif args.mode == "batch":
        print(f"è¾“å…¥ç›®å½•: {args.encoded_base_dir}")
        print(f"æœ€å¤§episodes: {args.max_episodes}")
        
        if not os.path.exists(args.encoded_base_dir):
            print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {args.encoded_base_dir}")
            return
        
        batch_decode_episodes(args.encoded_base_dir, args.vae_path, args.output_dir, args.max_episodes, args.device)

if __name__ == "__main__":
    main()