import torch
import numpy as np
from typing import List, Tuple

class PoseClassifier:
    """å°†poseå‚æ•°åˆ†ç±»ä¸ºå‰åŽå·¦å³å››ä¸ªç±»åˆ«ï¼Œæ­£ç¡®ä½¿ç”¨rotationæ•°æ®åˆ¤æ–­è½¬å¼¯"""
    
    def __init__(self):
        # å®šä¹‰å››ä¸ªæ–¹å‘çš„ç±»åˆ«
        self.FORWARD = 0
        self.BACKWARD = 1
        self.LEFT_TURN = 2
        self.RIGHT_TURN = 3
        
        self.class_names = ['forward', 'backward', 'left_turn', 'right_turn']
        
    def classify_pose_sequence(self, pose_sequence: torch.Tensor) -> torch.Tensor:
        """
        å¯¹poseåºåˆ—è¿›è¡Œåˆ†ç±»ï¼ŒåŸºäºŽç›¸å¯¹äºŽreferenceçš„poseå˜åŒ–
        Args:
            pose_sequence: [num_frames, 7] (relative_translation + relative_quaternion)
                          è¿™é‡Œçš„poseéƒ½æ˜¯ç›¸å¯¹äºŽreferenceå¸§çš„ç›¸å¯¹å˜æ¢
        Returns:
            classifications: [num_frames] ç±»åˆ«æ ‡ç­¾
        """
        # æå–å¹³ç§»éƒ¨åˆ† [num_frames, 3] å’Œæ—‹è½¬éƒ¨åˆ† [num_frames, 4]
        translations = pose_sequence[:, :3]  # ç›¸å¯¹äºŽreferenceçš„ä½ç§»
        rotations = pose_sequence[:, 3:7]    # ç›¸å¯¹äºŽreferenceçš„æ—‹è½¬ [w, x, y, z]
        
        # åˆ†ç±»æ¯ä¸€å¸§ - éƒ½æ˜¯ç›¸å¯¹äºŽreferenceå¸§çš„å˜åŒ–
        classifications = []
        for i in range(len(pose_sequence)):
            # ðŸ”§ ä¿®æ”¹ï¼šæ¯ä¸€å¸§éƒ½åŸºäºŽç›¸å¯¹äºŽreferenceçš„å˜åŒ–è¿›è¡Œåˆ†ç±»
            relative_translation = translations[i]  # ç›¸å¯¹äºŽreferenceçš„ä½ç§»
            relative_rotation = rotations[i]         # ç›¸å¯¹äºŽreferenceçš„æ—‹è½¬
            
            class_label = self._classify_single_pose(relative_translation, relative_rotation)
            classifications.append(class_label)
            
        return torch.tensor(classifications, dtype=torch.long)
    
    def _classify_single_pose(self, relative_translation: torch.Tensor, 
                            relative_rotation: torch.Tensor) -> int:
        """
        å¯¹å•ä¸ªposeè¿›è¡Œåˆ†ç±»ï¼ŒåŸºäºŽç›¸å¯¹äºŽreferenceçš„å˜åŒ–
        Args:
            relative_translation: [3] ç›¸å¯¹äºŽreferenceçš„ä½ç§»å˜åŒ–
            relative_rotation: [4] ç›¸å¯¹äºŽreferenceçš„æ—‹è½¬å››å…ƒæ•° [w, x, y, z]
        """
        # ðŸ”§ å…³é”®ï¼šä»Žç›¸å¯¹æ—‹è½¬å››å…ƒæ•°æå–yawè§’åº¦
        yaw_angle = self._quaternion_to_yaw(relative_rotation)
        
        # ðŸ”§ è®¡ç®—å‰è¿›/åŽé€€ï¼ˆä¸»è¦çœ‹xæ–¹å‘çš„ä½ç§»ï¼‰
        forward_movement = -relative_translation[0].item()  # xè´Ÿæ–¹å‘ä¸ºå‰è¿›
        
        # ðŸ”§ è®¾ç½®é˜ˆå€¼
        yaw_threshold = 0.05  # çº¦2.9åº¦ï¼Œå¯ä»¥è°ƒæ•´
        movement_threshold = 0.01  # ä½ç§»é˜ˆå€¼
        
        # ðŸ”§ ä¼˜å…ˆåˆ¤æ–­è½¬å¼¯ï¼ˆåŸºäºŽç›¸å¯¹äºŽreferenceçš„yawè§’åº¦ï¼‰
        if abs(yaw_angle) > yaw_threshold:
            if yaw_angle > 0:
                return self.LEFT_TURN   # æ­£yawè§’åº¦ä¸ºå·¦è½¬
            else:
                return self.RIGHT_TURN  # è´Ÿyawè§’åº¦ä¸ºå³è½¬
        
        # ðŸ”§ å¦‚æžœæ²¡æœ‰æ˜Žæ˜¾è½¬å¼¯ï¼Œåˆ¤æ–­å‰è¿›åŽé€€ï¼ˆåŸºäºŽç›¸å¯¹ä½ç§»ï¼‰
        if abs(forward_movement) > movement_threshold:
            if forward_movement > 0:
                return self.FORWARD
            else:
                return self.BACKWARD
        
        # ðŸ”§ å¦‚æžœä½ç§»å’Œæ—‹è½¬éƒ½å¾ˆå°ï¼Œåˆ¤æ–­ä¸ºå‰è¿›ï¼ˆé™æ­¢æ—¶çš„é»˜è®¤çŠ¶æ€ï¼‰
        return self.FORWARD
    
    def _quaternion_to_yaw(self, q: torch.Tensor) -> float:
        """
        ä»Žå››å…ƒæ•°æå–yawè§’åº¦ï¼ˆç»•zè½´æ—‹è½¬ï¼‰
        Args:
            q: [4] å››å…ƒæ•° [w, x, y, z]
        Returns:
            yaw: yawè§’åº¦ï¼ˆå¼§åº¦ï¼‰
        """
        try:
            # è½¬æ¢ä¸ºnumpyæ•°ç»„è¿›è¡Œè®¡ç®—
            q_np = q.detach().cpu().numpy()
            
            # ðŸ”§ ç¡®ä¿å››å…ƒæ•°æ˜¯å•ä½å››å…ƒæ•°
            norm = np.linalg.norm(q_np)
            if norm > 1e-8:
                q_np = q_np / norm
            else:
                # å¦‚æžœå››å…ƒæ•°æŽ¥è¿‘é›¶ï¼Œè¿”å›ž0è§’åº¦
                return 0.0
            
            w, x, y, z = q_np
            
            # ðŸ”§ è®¡ç®—yawè§’åº¦ï¼šatan2(2*(w*z + x*y), 1 - 2*(y^2 + z^2))
            yaw = np.arctan2(2.0 * (w*z + x*y), 1.0 - 2.0 * (y*y + z*z))
            
            return float(yaw)
            
        except Exception as e:
            print(f"Error computing yaw from quaternion: {e}")
            return 0.0
    
    def create_class_embedding(self, class_labels: torch.Tensor, embed_dim: int = 512) -> torch.Tensor:
        """
        ä¸ºç±»åˆ«æ ‡ç­¾åˆ›å»ºembedding
        Args:
            class_labels: [num_frames] ç±»åˆ«æ ‡ç­¾
            embed_dim: embeddingç»´åº¦
        Returns:
            embeddings: [num_frames, embed_dim]
        """
        num_classes = 4
        num_frames = len(class_labels)
        
        # ðŸ”§ åˆ›å»ºæ›´æœ‰æ„ä¹‰çš„embeddingï¼Œä¸åŒç±»åˆ«æœ‰ä¸åŒçš„ç‰¹å¾
        # ä½¿ç”¨é¢„å®šä¹‰çš„æ–¹å‘å‘é‡
        direction_vectors = torch.tensor([
            [1.0, 0.0, 0.0, 0.0],  # forward: ä¸»è¦xåˆ†é‡
            [-1.0, 0.0, 0.0, 0.0], # backward: è´Ÿxåˆ†é‡  
            [0.0, 1.0, 0.0, 0.0],  # left_turn: ä¸»è¦yåˆ†é‡
            [0.0, -1.0, 0.0, 0.0], # right_turn: è´Ÿyåˆ†é‡
        ], dtype=torch.float32)
        
        # One-hotç¼–ç 
        one_hot = torch.zeros(num_frames, num_classes)
        one_hot.scatter_(1, class_labels.unsqueeze(1), 1)
        
        # åŸºäºŽæ–¹å‘å‘é‡çš„åŸºç¡€embedding
        base_embeddings = one_hot @ direction_vectors  # [num_frames, 4]
        
        # æ‰©å±•åˆ°ç›®æ ‡ç»´åº¦
        if embed_dim > 4:
            # ä½¿ç”¨çº¿æ€§å˜æ¢æ‰©å±•
            expand_matrix = torch.randn(4, embed_dim) * 0.1
            # ä¿æŒæ–¹å‘æ€§
            expand_matrix[:4, :4] = torch.eye(4)
            embeddings = base_embeddings @ expand_matrix
        else:
            embeddings = base_embeddings[:, :embed_dim]
        
        return embeddings
    
    def get_class_name(self, class_id: int) -> str:
        """èŽ·å–ç±»åˆ«åç§°"""
        return self.class_names[class_id]
    
    def analyze_pose_sequence(self, pose_sequence: torch.Tensor) -> dict:
        """
        åˆ†æžposeåºåˆ—ï¼Œè¿”å›žè¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯
        Args:
            pose_sequence: [num_frames, 7] (translation + quaternion)
        Returns:
            analysis: åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        classifications = self.classify_pose_sequence(pose_sequence)
        
        # ç»Ÿè®¡å„ç±»åˆ«æ•°é‡
        class_counts = torch.bincount(classifications, minlength=4)
        
        # è®¡ç®—è¿žç»­è¿åŠ¨æ®µ
        motion_segments = []
        if len(classifications) > 0:
            current_class = classifications[0].item()
            segment_start = 0
            
            for i in range(1, len(classifications)):
                if classifications[i].item() != current_class:
                    motion_segments.append({
                        'class': self.get_class_name(current_class),
                        'start_frame': segment_start,
                        'end_frame': i-1,
                        'duration': i - segment_start
                    })
                    current_class = classifications[i].item()
                    segment_start = i
            
            # æ·»åŠ æœ€åŽä¸€ä¸ªæ®µ
            motion_segments.append({
                'class': self.get_class_name(current_class),
                'start_frame': segment_start,
                'end_frame': len(classifications)-1,
                'duration': len(classifications) - segment_start
            })
        
        # è®¡ç®—æ€»ä½“è¿åŠ¨ä¿¡æ¯
        translations = pose_sequence[:, :3]
        if len(translations) > 1:
            # è®¡ç®—ç´¯ç§¯è·ç¦»ï¼ˆç›¸å¯¹äºŽreferenceçš„æ€»ç§»åŠ¨è·ç¦»ï¼‰
            total_distance = torch.norm(translations[-1] - translations[0])
        else:
            total_distance = torch.tensor(0.0)
        
        analysis = {
            'total_frames': len(pose_sequence),
            'class_distribution': {
                self.get_class_name(i): count.item() 
                for i, count in enumerate(class_counts)
            },
            'motion_segments': motion_segments,
            'total_distance': total_distance.item(),
            'classifications': classifications
        }
        
        return analysis
    
    def debug_single_pose(self, relative_translation: torch.Tensor, 
                         relative_rotation: torch.Tensor) -> dict:
        """
        è°ƒè¯•å•ä¸ªposeçš„åˆ†ç±»è¿‡ç¨‹
        Args:
            relative_translation: [3] ç›¸å¯¹ä½ç§»
            relative_rotation: [4] ç›¸å¯¹æ—‹è½¬å››å…ƒæ•°
        Returns:
            debug_info: è°ƒè¯•ä¿¡æ¯å­—å…¸
        """
        yaw_angle = self._quaternion_to_yaw(relative_rotation)
        forward_movement = -relative_translation[0].item()
        
        yaw_threshold = 0.05
        movement_threshold = 0.01
        
        classification = self._classify_single_pose(relative_translation, relative_rotation)
        
        debug_info = {
            'relative_translation': relative_translation.tolist(),
            'relative_rotation': relative_rotation.tolist(),
            'yaw_angle_rad': yaw_angle,
            'yaw_angle_deg': np.degrees(yaw_angle),
            'forward_movement': forward_movement,
            'yaw_threshold': yaw_threshold,
            'movement_threshold': movement_threshold,
            'classification': self.get_class_name(classification),
            'classification_id': classification,
            'decision_process': {
                'abs_yaw_exceeds_threshold': abs(yaw_angle) > yaw_threshold,
                'abs_movement_exceeds_threshold': abs(forward_movement) > movement_threshold,
                'yaw_direction': 'left' if yaw_angle > 0 else 'right' if yaw_angle < 0 else 'none',
                'movement_direction': 'forward' if forward_movement > 0 else 'backward' if forward_movement < 0 else 'none'
            }
        }
        
        return debug_info